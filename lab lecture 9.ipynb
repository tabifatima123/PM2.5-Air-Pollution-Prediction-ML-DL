{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAratfsozj4z",
        "outputId": "dd1070bc-250e-4017-98c4-28659c2e01a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PM columns: ['OBJECTID', 'station', 'pm_2_5', 'Latitude', 'Longitude', 'x', 'y']\n",
            "   OBJECTID   station  pm_2_5      Latitude    Longitude            x  \\\n",
            "0         2  aghsasie    24.0  3.961416e+06  543746.7260  543746.7260   \n",
            "1         3  park roz    27.0  3.955132e+06  524222.9926  524222.9926   \n",
            "2         4    poonak    21.0  3.957635e+06  529983.0336  529983.0336   \n",
            "3         5    pirozi    34.0  3.950342e+06  544671.7644  544671.7644   \n",
            "4         6   tarbiat    33.0  3.952686e+06  534904.7643  534904.7643   \n",
            "\n",
            "              y  \n",
            "0  3.961416e+06  \n",
            "1  3.955132e+06  \n",
            "2  3.957635e+06  \n",
            "3  3.950342e+06  \n",
            "4  3.952686e+06  \n"
          ]
        }
      ],
      "source": [
        "GIS_DIR = \"/content/Data_GIS_New/Data GIS\"  \n",
        "\n",
        "# find the PM2.5 shapefile\n",
        "pm_shp = None\n",
        "for p in glob.glob(os.path.join(GIS_DIR, \"*.shp\")):\n",
        "    if os.path.basename(p).lower().startswith(\"pm2.5\"):\n",
        "        pm_shp = p\n",
        "        break\n",
        "assert pm_shp is not None, \"PM2.5.shp not found in GIS_DIR.\"\n",
        "\n",
        "# read shapefile (pyshp)\n",
        "r = shapefile.Reader(pm_shp)\n",
        "fields = [f[0] for f in r.fields if f[0] != \"DeletionFlag\"]\n",
        "recs = r.records()\n",
        "shps = r.shapes()\n",
        "\n",
        "# build dataframe with attributes + coords (x,y)\n",
        "rows = []\n",
        "for rec, shp in zip(recs, shps):\n",
        "    attrs = dict(zip(fields, rec))\n",
        "    # take first point (assuming point shapefile)\n",
        "    x, y = shp.points[0]\n",
        "    attrs.update({\"x\": x, \"y\": y})\n",
        "    rows.append(attrs)\n",
        "\n",
        "pm_df = pd.DataFrame(rows)\n",
        "print(\"PM columns:\", pm_df.columns.tolist())\n",
        "print(pm_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaxNaHMfzoF1",
        "outputId": "c4b66f6a-482d-49a4-81c5-f4c6ee42115e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector CRS: PROJCS[\"WGS_1984_UTM_Zone_39N\",GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"false_easting\",500000.0],PARAMETER[\"false_northing\",0.0],PARAMETER[\"central_meridian\",51.0],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"latitude_of_origin\",0.0],UNIT[\"Meter\",1.0]]\n"
          ]
        }
      ],
      "source": [
        "# read shapefile CRS from .prj (if present)\n",
        "prj_path = pm_shp.replace(\".shp\", \".prj\")\n",
        "crs_vec = CRS.from_wkt(open(prj_path).read()) if os.path.exists(prj_path) else None\n",
        "print(\"Vector CRS:\", crs_vec)\n",
        "\n",
        "def make_transformer(crs_from, crs_to):\n",
        "    if (crs_from is None) or (crs_to is None):\n",
        "        return None\n",
        "    if CRS.from_user_input(crs_from) == CRS.from_user_input(crs_to):\n",
        "        return None\n",
        "    return Transformer.from_crs(crs_from, crs_to, always_xy=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQT1D0USzzJ0",
        "outputId": "f97349cd-f64f-4dc1-93cd-1652908de0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rasters found: ['Population density', 'Wind speed', 'Rainfall', 'NDVI', 'Temperature', 'Humidity', 'Distance to street', 'Distance to industrial', 'Elevation']\n",
            "Sampled: NDVI -> ndvi\n",
            "Sampled: Temperature -> temp\n",
            "Sampled: Humidity -> humidity\n",
            "Sampled: Rainfall -> rain\n",
            "Sampled: Wind speed -> wind\n",
            "Sampled: Population density -> pop_density\n",
            "   OBJECTID   station  pm_2_5      Latitude    Longitude            x  \\\n",
            "0         2  aghsasie    24.0  3.961416e+06  543746.7260  543746.7260   \n",
            "1         3  park roz    27.0  3.955132e+06  524222.9926  524222.9926   \n",
            "2         4    poonak    21.0  3.957635e+06  529983.0336  529983.0336   \n",
            "3         5    pirozi    34.0  3.950342e+06  544671.7644  544671.7644   \n",
            "4         6   tarbiat    33.0  3.952686e+06  534904.7643  534904.7643   \n",
            "\n",
            "              y      ndvi       temp   humidity        rain      wind  \\\n",
            "0  3.961416e+06  0.186091  16.381969  39.679241  325.161865  2.164852   \n",
            "1  3.955132e+06  0.231287  17.617378  36.651649  251.852448  2.541904   \n",
            "2  3.957635e+06  0.171851  17.537899  36.835045  273.974121  2.214953   \n",
            "3  3.950342e+06  0.070099  15.905035  41.332394  394.644257  1.235514   \n",
            "4  3.952686e+06  0.049471  17.555529  36.868725  284.113342  2.023376   \n",
            "\n",
            "   pop_density  \n",
            "0    48.801765  \n",
            "1    25.537809  \n",
            "2     2.087641  \n",
            "3     2.202320  \n",
            "4     0.000000  \n"
          ]
        }
      ],
      "source": [
        "# collect raster files (ignore .ovr)\n",
        "rasters = {}\n",
        "for path in glob.glob(os.path.join(GIS_DIR, \"*.tif\")):\n",
        "    name = os.path.splitext(os.path.basename(path))[0]\n",
        "    if name.endswith(\".tif\"): name = name[:-4]\n",
        "    rasters[name] = path\n",
        "\n",
        "print(\"Rasters found:\", list(rasters.keys()))\n",
        "\n",
        "def sample_raster_column(df, xcol, ycol, ras_path, out_col):\n",
        "    with rasterio.open(ras_path) as ds:\n",
        "        tx = make_transformer(crs_vec, ds.crs)\n",
        "        if tx is not None:\n",
        "            pts = [tx.transform(x, y) for x, y in zip(df[xcol].values, df[ycol].values)]\n",
        "        else:\n",
        "            pts = list(zip(df[xcol].values, df[ycol].values))\n",
        "        # ds.sample expects [(x,y), ...] in raster CRS\n",
        "        vals = list(ds.sample(pts))\n",
        "        vals = [float(v[0]) if (v is not None and len(v)) else np.nan for v in vals]\n",
        "    df[out_col] = vals\n",
        "    return df\n",
        "\n",
        "# Map friendly names (adjust if you want different labels)\n",
        "name_map = {\n",
        "    \"NDVI\": \"ndvi\",\n",
        "    \"Temperature\": \"temp\",\n",
        "    \"Humidity\": \"humidity\",\n",
        "    \"Rainfall\": \"rain\",\n",
        "    \"Wind speed\": \"wind\",\n",
        "    \"Population density\": \"pop_density\",\n",
        "}\n",
        "for key, col in name_map.items():\n",
        "    # find raster key that matches (case-insensitive, space-insensitive)\n",
        "    cand = next((k for k in rasters if k.lower().replace(\" \",\"\") == key.lower().replace(\" \",\"\")), None)\n",
        "    if cand:\n",
        "        pm_df = sample_raster_column(pm_df, \"x\", \"y\", rasters[cand], col)\n",
        "        print(f\"Sampled: {key} -> {col}\")\n",
        "    else:\n",
        "        print(f\"Missing raster for: {key}\")\n",
        "\n",
        "print(pm_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8c047plz39N",
        "outputId": "8e32a0e1-678c-4ae7-8968-a0199418f784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PM-candidate columns: ['pm_2_5']\n",
            "Saved: /content/station_static_features.csv\n"
          ]
        }
      ],
      "source": [
        "# try to guess PM column name; change \"PM_value\" below if needed\n",
        "# Look through columns for a PM-ish field:\n",
        "pm_candidates = [c for c in pm_df.columns if c.lower().startswith(\"pm\")]\n",
        "print(\"PM-candidate columns:\", pm_candidates)\n",
        "\n",
        "OUT_CSV = \"/content/station_static_features.csv\"\n",
        "pm_df.to_csv(OUT_CSV, index=False)\n",
        "print(\"Saved:\", OUT_CSV)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6Ccn6CGzK9P",
        "outputId": "c6a9ba01-359c-46bb-ad86-052ce3ec438a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   OBJECTID   station  pm_2_5      Latitude    Longitude            x  \\\n",
            "0         2  aghsasie    24.0  3.961416e+06  543746.7260  543746.7260   \n",
            "1         3  park roz    27.0  3.955132e+06  524222.9926  524222.9926   \n",
            "2         4    poonak    21.0  3.957635e+06  529983.0336  529983.0336   \n",
            "3         5    pirozi    34.0  3.950342e+06  544671.7644  544671.7644   \n",
            "4         6   tarbiat    33.0  3.952686e+06  534904.7643  534904.7643   \n",
            "\n",
            "              y      ndvi       temp   humidity        rain      wind  \\\n",
            "0  3.961416e+06  0.186091  16.381969  39.679241  325.161865  2.164852   \n",
            "1  3.955132e+06  0.231287  17.617378  36.651649  251.852448  2.541904   \n",
            "2  3.957635e+06  0.171851  17.537899  36.835045  273.974121  2.214953   \n",
            "3  3.950342e+06  0.070099  15.905035  41.332394  394.644257  1.235514   \n",
            "4  3.952686e+06  0.049471  17.555529  36.868725  284.113342  2.023376   \n",
            "\n",
            "   pop_density  pm_2_5_smooth  \n",
            "0    48.801765      23.476190  \n",
            "1    25.537809      24.714286  \n",
            "2     2.087641      26.190476  \n",
            "3     2.202320      31.523810  \n",
            "4     0.000000      34.333333  \n"
          ]
        }
      ],
      "source": [
        "from scipy.signal import savgol_filter\n",
        "from scipy.interpolate import UnivariateSpline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load back the dataset we just saved\n",
        "df = pd.read_csv(\"/content/station_static_features.csv\")\n",
        "\n",
        "# --- Savitzky–Golay smoothing on PM2.5 ---\n",
        "df[\"pm_2_5_smooth\"] = savgol_filter(df[\"pm_2_5\"], window_length=7, polyorder=2, mode=\"nearest\")\n",
        "\n",
        "# --- Example: spline interpolation for missing values in predictors ---\n",
        "def spline_fill(series):\n",
        "    x = np.arange(len(series))\n",
        "    mask = ~np.isnan(series)\n",
        "    if mask.sum() < 4:   # not enough points for spline\n",
        "        return series.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
        "    spline = UnivariateSpline(x[mask], series[mask], k=3, s=0)\n",
        "    return spline(x)\n",
        "\n",
        "for col in [\"temp\", \"humidity\", \"rain\", \"wind\", \"ndvi\"]:\n",
        "    if df[col].isna().any():\n",
        "        df[col] = spline_fill(df[col].values)\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1TSYeem0VgC",
        "outputId": "eaa2881e-4888-4eb8-a866-31e763b3bb46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   OBJECTID   station  pm_2_5      Latitude    Longitude            x  \\\n",
            "0         2  aghsasie    24.0  3.961416e+06  543746.7260  543746.7260   \n",
            "1         3  park roz    27.0  3.955132e+06  524222.9926  524222.9926   \n",
            "2         4    poonak    21.0  3.957635e+06  529983.0336  529983.0336   \n",
            "3         5    pirozi    34.0  3.950342e+06  544671.7644  544671.7644   \n",
            "4         6   tarbiat    33.0  3.952686e+06  534904.7643  534904.7643   \n",
            "\n",
            "              y      ndvi       temp   humidity        rain      wind  \\\n",
            "0  3.961416e+06  0.186091  16.381969  39.679241  325.161865  2.164852   \n",
            "1  3.955132e+06  0.231287  17.617378  36.651649  251.852448  2.541904   \n",
            "2  3.957635e+06  0.171851  17.537899  36.835045  273.974121  2.214953   \n",
            "3  3.950342e+06  0.070099  15.905035  41.332394  394.644257  1.235514   \n",
            "4  3.952686e+06  0.049471  17.555529  36.868725  284.113342  2.023376   \n",
            "\n",
            "   pop_density  pm_2_5_smooth  temp_idw  humidity_idw  wind_idw  rain_idw  \n",
            "0    48.801765      23.476190     16.56          39.0      2.22     298.0  \n",
            "1    25.537809      24.714286     16.56          39.0      2.22     298.0  \n",
            "2     2.087641      26.190476     16.56          39.0      2.22     298.0  \n",
            "3     2.202320      31.523810     16.56          39.0      2.22     298.0  \n",
            "4     0.000000      34.333333     16.56          39.0      2.22     298.0  \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# IDW interpolation function\n",
        "def idw_interpolation(xy_known, values, xy_target, power=2):\n",
        "    \"\"\"Inverse Distance Weighting (IDW) interpolation.\"\"\"\n",
        "    dists = np.linalg.norm(xy_known - xy_target, axis=1)\n",
        "    weights = 1 / (dists**power + 1e-8)  # avoid division by zero\n",
        "    return np.sum(weights * values) / np.sum(weights)\n",
        "\n",
        "# Example: suppose you have 5 meteorological stations dataframe\n",
        "# (replace with your actual met data table)\n",
        "met_stations = pd.DataFrame({\n",
        "    \"Longitude\": [51.3, 51.4, 51.5, 51.6, 51.7],\n",
        "    \"Latitude\": [35.7, 35.8, 35.9, 36.0, 36.1],\n",
        "    \"temp\": [17.0, 16.5, 15.8, 16.2, 17.3],\n",
        "    \"humidity\": [40, 38, 37, 41, 39],\n",
        "    \"wind\": [2.2, 2.5, 2.0, 2.3, 2.1],\n",
        "    \"rain\": [300, 280, 310, 295, 305]\n",
        "})\n",
        "\n",
        "# Convert to numpy coords\n",
        "xy_known = met_stations[[\"Longitude\", \"Latitude\"]].values\n",
        "\n",
        "# Apply IDW to each AQ station\n",
        "for var in [\"temp\", \"humidity\", \"wind\", \"rain\"]:\n",
        "    interpolated = []\n",
        "    for i, row in df.iterrows():\n",
        "        xy_target = np.array([row[\"Longitude\"], row[\"Latitude\"]])\n",
        "        value = idw_interpolation(xy_known, met_stations[var].values, xy_target)\n",
        "        interpolated.append(value)\n",
        "    df[var + \"_idw\"] = interpolated\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGHnj7FU0_Ln",
        "outputId": "5ab78036-7254-406b-d327-62bb7bdb402e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spatial hold-out stations: ['aghsasie', 'shahrdari11', 'sharif', 'park roz']\n",
            "Train rows: 18, Test rows: 22\n",
            "Feature matrix shape: (18, 6) Target shape: (18,)\n"
          ]
        }
      ],
      "source": [
        "# ==== Temporal + Spatial split ====\n",
        "import numpy as np\n",
        "\n",
        "df_split = df.copy()\n",
        "\n",
        "# Prefer IDW meteorological features\n",
        "feature_cols = [\"temp_idw\", \"humidity_idw\", \"wind_idw\", \"rain_idw\",\n",
        "                \"ndvi\", \"pop_density\"]\n",
        "\n",
        "# Use smoothed PM2.5 as target\n",
        "target_col = \"pm_2_5_smooth\"\n",
        "\n",
        "# If you already have a \"date\" column, activate year-based split\n",
        "if \"date\" in df_split.columns:\n",
        "    df_split[\"date\"] = pd.to_datetime(df_split[\"date\"])\n",
        "    df_split[\"year\"] = df_split[\"date\"].dt.year\n",
        "else:\n",
        "    # Dummy year column (all NaN) → only spatial split will apply\n",
        "    df_split[\"year\"] = np.nan\n",
        "\n",
        "# Temporal split (2014–2015 train, 2016 test)\n",
        "temporal_train_mask = df_split[\"year\"].between(2014, 2015) if df_split[\"year\"].notna().any() else pd.Series(True, index=df_split.index)\n",
        "temporal_test_mask  = df_split[\"year\"] == 2016              if df_split[\"year\"].notna().any() else pd.Series(True, index=df_split.index)\n",
        "\n",
        "# Spatial split (hold out 20% of stations)\n",
        "rng = np.random.RandomState(42)\n",
        "stations = df_split[\"station\"].astype(str).unique()\n",
        "n_holdout = max(1, int(0.2 * len(stations)))\n",
        "holdout_stations = rng.choice(stations, size=n_holdout, replace=False).tolist()\n",
        "print(\"Spatial hold-out stations:\", holdout_stations)\n",
        "\n",
        "spatial_holdout_mask = df_split[\"station\"].astype(str).isin(holdout_stations)\n",
        "\n",
        "# Train = temporal train years & not in spatial holdout\n",
        "train_mask = temporal_train_mask & (~spatial_holdout_mask)\n",
        "# Test = temporal test year OR spatial holdout stations\n",
        "test_mask = temporal_test_mask | spatial_holdout_mask\n",
        "\n",
        "train_df = df_split.loc[train_mask].reset_index(drop=True)\n",
        "test_df  = df_split.loc[test_mask].reset_index(drop=True)\n",
        "\n",
        "print(f\"Train rows: {len(train_df)}, Test rows: {len(test_df)}\")\n",
        "\n",
        "X_train = train_df[feature_cols].values\n",
        "y_train = train_df[target_col].values\n",
        "X_test  = test_df[feature_cols].values\n",
        "y_test  = test_df[target_col].values\n",
        "\n",
        "print(\"Feature matrix shape:\", X_train.shape, \"Target shape:\", y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9ltHzE21FME",
        "outputId": "1678881b-a3c8-465c-f45f-99b159d6f840"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaled shapes: (18, 6) (22, 6)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s  = scaler.transform(X_test)\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2   = r2_score(y_true, y_pred)\n",
        "    sd   = np.std(y_true - y_pred)\n",
        "    return {\"RMSE\": float(rmse), \"R2\": float(r2), \"SD\": float(sd)}\n",
        "\n",
        "print(\"Scaled shapes:\", X_train_s.shape, X_test_s.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDSjhX3h1QdS",
        "outputId": "4162fba6-9482-4fcb-f730-2f3f7458d5e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest: {'RMSE': 3.2659205414723176, 'R2': 0.49848535508258907, 'SD': 3.2396363061433413}\n",
            "SVM: {'RMSE': 3.9655513932073716, 'R2': 0.26059981272135535, 'SD': 3.965551392991338}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# ---- Random Forest baseline ----\n",
        "rf = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train_s, y_train)\n",
        "pred_rf = rf.predict(X_test_s)\n",
        "print(\"Random Forest:\", evaluate(y_test, pred_rf))\n",
        "\n",
        "# ---- SVM baseline ----\n",
        "svm = SVR(kernel=\"rbf\", C=10.0, gamma=\"scale\")\n",
        "svm.fit(X_train_s, y_train)\n",
        "pred_svm = svm.predict(X_test_s)\n",
        "print(\"SVM:\", evaluate(y_test, pred_svm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B29amSl31VNi",
        "outputId": "7187e746-e709-48e4-8363-8263f843f3a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "DNN: {'RMSE': 20.46603823459775, 'R2': -18.694272973079926, 'SD': 8.417741013413849}\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# ---- DNN baseline ----\n",
        "dnn = Sequential([\n",
        "    Dense(64, activation=\"relu\", input_shape=(X_train_s.shape[1],)),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(1)\n",
        "])\n",
        "dnn.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "dnn.fit(X_train_s, y_train, epochs=50, batch_size=8, verbose=0,\n",
        "        validation_data=(X_test_s, y_test))\n",
        "\n",
        "pred_dnn = dnn.predict(X_test_s).ravel()\n",
        "print(\"DNN:\", evaluate(y_test, pred_dnn))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGGfbMF41jbr",
        "outputId": "91afa5bf-b2c2-45b3-de36-71c0cf86662b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
            "RNN: {'RMSE': 30.957073531459006, 'R2': -44.06010385772256, 'SD': 4.561611884384506}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "LSTM: {'RMSE': 31.287072561060288, 'R2': -45.025895776317135, 'SD': 4.721313452882025}\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import SimpleRNN, LSTM, Reshape\n",
        "\n",
        "# ---- Reshape for RNN/LSTM ----\n",
        "X_train_seq = X_train_s.reshape((X_train_s.shape[0], 1, X_train_s.shape[1]))\n",
        "X_test_seq  = X_test_s.reshape((X_test_s.shape[0], 1, X_test_s.shape[1]))\n",
        "\n",
        "# ---- Simple RNN baseline ----\n",
        "rnn = Sequential([\n",
        "    SimpleRNN(32, input_shape=(1, X_train_s.shape[1])),\n",
        "    Dense(1)\n",
        "])\n",
        "rnn.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "rnn.fit(X_train_seq, y_train, epochs=50, batch_size=8, verbose=0,\n",
        "        validation_data=(X_test_seq, y_test))\n",
        "\n",
        "pred_rnn = rnn.predict(X_test_seq).ravel()\n",
        "print(\"RNN:\", evaluate(y_test, pred_rnn))\n",
        "\n",
        "# ---- LSTM baseline ----\n",
        "lstm = Sequential([\n",
        "    LSTM(32, input_shape=(1, X_train_s.shape[1])),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "lstm.fit(X_train_seq, y_train, epochs=50, batch_size=8, verbose=0,\n",
        "         validation_data=(X_test_seq, y_test))\n",
        "\n",
        "pred_lstm = lstm.predict(X_test_seq).ravel()\n",
        "print(\"LSTM:\", evaluate(y_test, pred_lstm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scHZYD7B3l8z",
        "outputId": "542525c1-e3b2-42f5-df45-d56733ed9bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "DNN (fixed): {'RMSE': 14.708908980632525, 'R2': -9.172631485066228, 'SD': 11.682091407398493}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7cd18528a160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
            "RNN: {'RMSE': 21.494907546797634, 'R2': -20.724188068356536, 'SD': 4.46384020702864}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7cd184f076a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "LSTM: {'RMSE': 24.888530253678866, 'R2': -28.125332544411624, 'SD': 4.343886208501631}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# DNN (with proper Input layer)\n",
        "dnn = Sequential([\n",
        "    Input(shape=(X_train_s.shape[1],)),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(16, activation=\"relu\"),\n",
        "    Dense(1)\n",
        "])\n",
        "dnn.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "dnn.fit(\n",
        "    X_train_s, y_train,\n",
        "    validation_split=0.25,\n",
        "    epochs=200, batch_size=4, verbose=0,\n",
        "    callbacks=[EarlyStopping(patience=20, restore_best_weights=True)]\n",
        ")\n",
        "pred_dnn = dnn.predict(X_test_s).ravel()\n",
        "print(\"DNN (fixed):\", evaluate(y_test, pred_dnn))\n",
        "\n",
        "# Prep simple seq shaped inputs (seq_len=1 to match tabular)\n",
        "X_train_seq = X_train_s.reshape((X_train_s.shape[0], 1, X_train_s.shape[1]))\n",
        "X_test_seq  = X_test_s.reshape((X_test_s.shape[0], 1, X_test_s.shape[1]))\n",
        "\n",
        "# RNN\n",
        "rnn = Sequential([\n",
        "    Input(shape=(1, X_train_s.shape[1])),\n",
        "    SimpleRNN(16),\n",
        "    Dense(1)\n",
        "])\n",
        "rnn.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "rnn.fit(\n",
        "    X_train_seq, y_train,\n",
        "    validation_split=0.25,\n",
        "    epochs=200, batch_size=4, verbose=0,\n",
        "    callbacks=[EarlyStopping(patience=20, restore_best_weights=True)]\n",
        ")\n",
        "pred_rnn = rnn.predict(X_test_seq).ravel()\n",
        "print(\"RNN:\", evaluate(y_test, pred_rnn))\n",
        "\n",
        "# LSTM\n",
        "lstm = Sequential([\n",
        "    Input(shape=(1, X_train_s.shape[1])),\n",
        "    LSTM(16),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "lstm.fit(\n",
        "    X_train_seq, y_train,\n",
        "    validation_split=0.25,\n",
        "    epochs=200, batch_size=4, verbose=0,\n",
        "    callbacks=[EarlyStopping(patience=20, restore_best_weights=True)]\n",
        ")\n",
        "pred_lstm = lstm.predict(X_test_seq).ravel()\n",
        "print(\"LSTM:\", evaluate(y_test, pred_lstm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQwFOpTs4oav",
        "outputId": "8b4b6148-714c-4061-d558-60dff8d7fd50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gen 1/6 — best CV RMSE: 29.9684 | best params: {'units': 16, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 8, 'epochs': 180}\n",
            "Gen 2/6 — best CV RMSE: 29.2229 | best params: {'units': 24, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 8, 'epochs': 180}\n",
            "Gen 3/6 — best CV RMSE: 26.3129 | best params: {'units': 32, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 4, 'epochs': 180}\n",
            "Gen 4/6 — best CV RMSE: 26.3129 | best params: {'units': 32, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 4, 'epochs': 180}\n",
            "Gen 5/6 — best CV RMSE: 26.3129 | best params: {'units': 32, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 4, 'epochs': 180}\n",
            "Gen 6/6 — best CV RMSE: 26.2835 | best params: {'units': 32, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 4, 'epochs': 180}\n",
            "OA done in 3478.7s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "({'units': 32, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 4, 'epochs': 180},\n",
              " 26.283480190963733)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import copy, random, time\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "# Search space (keep small given tiny data)\n",
        "PARAM_SPACE = {\n",
        "    \"units\":      [8, 16, 24, 32],\n",
        "    \"dropout\":    [0.0, 0.1, 0.2, 0.3],\n",
        "    \"lr\":         [1e-3, 5e-4, 1e-4],\n",
        "    \"batch_size\": [4, 8, 16],\n",
        "    \"epochs\":     [80, 120, 180]\n",
        "}\n",
        "\n",
        "def build_lstm(input_shape, units=16, dropout=0.1, lr=1e-3):\n",
        "    m = tf.keras.Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(units),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    m.compile(optimizer=Adam(learning_rate=lr), loss=\"mse\")\n",
        "    return m\n",
        "\n",
        "def cv_rmse_lstm(params, X_seq, y, n_splits=3):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    rmses = []\n",
        "    for tr, va in kf.split(X_seq):\n",
        "        X_tr, X_va = X_seq[tr], X_seq[va]\n",
        "        y_tr, y_va = y[tr], y[va]\n",
        "\n",
        "        model = build_lstm(\n",
        "            input_shape=(X_seq.shape[1], X_seq.shape[2]),\n",
        "            units=params[\"units\"], dropout=params[\"dropout\"], lr=params[\"lr\"]\n",
        "        )\n",
        "        es = EarlyStopping(patience=15, restore_best_weights=True)\n",
        "        model.fit(\n",
        "            X_tr, y_tr,\n",
        "            validation_data=(X_va, y_va),\n",
        "            epochs=params[\"epochs\"],\n",
        "            batch_size=params[\"batch_size\"],\n",
        "            verbose=0,\n",
        "            callbacks=[es]\n",
        "        )\n",
        "        pred = model.predict(X_va, verbose=0).ravel()\n",
        "        rmses.append(np.sqrt(mean_squared_error(y_va, pred)))\n",
        "    return float(np.mean(rmses))\n",
        "\n",
        "def random_params():\n",
        "    return {k: random.choice(v) for k, v in PARAM_SPACE.items()}\n",
        "\n",
        "def mutate(params, strength=1):\n",
        "    newp = copy.deepcopy(params)\n",
        "    for _ in range(strength):\n",
        "        key = random.choice(list(PARAM_SPACE.keys()))\n",
        "        newp[key] = random.choice(PARAM_SPACE[key])\n",
        "    return newp\n",
        "\n",
        "def orchard_optimize(X_train_s, y_train, pop=10, gens=6, elite=3):\n",
        "    # reshape to (N, 1, F)\n",
        "    X_seq = X_train_s.reshape((X_train_s.shape[0], 1, X_train_s.shape[1]))\n",
        "    population = [random_params() for _ in range(pop)]\n",
        "    history = []\n",
        "    best = None\n",
        "\n",
        "    for g in range(gens):\n",
        "        scored = []\n",
        "        for p in population:\n",
        "            score = cv_rmse_lstm(p, X_seq, y_train, n_splits=3)\n",
        "            scored.append((score, p))\n",
        "        scored.sort(key=lambda x: x[0])\n",
        "        best = scored[0] if (best is None or scored[0][0] < best[0]) else best\n",
        "        history.append(best[0])\n",
        "\n",
        "        # Elitism (keep top-k)\n",
        "        elites = [copy.deepcopy(p) for _, p in scored[:elite]]\n",
        "\n",
        "        # Growth + Grafting: mutate elites to explore neighbors\n",
        "        mutants = [mutate(p, strength=1) for p in elites] + [mutate(p, strength=2) for p in elites]\n",
        "\n",
        "        # Screening + Pruning: add a few random fresh shoots (diversity) and trim worst\n",
        "        fresh = [random_params() for _ in range(max(0, pop - len(elites) - len(mutants)))]\n",
        "\n",
        "        population = elites + mutants + fresh\n",
        "\n",
        "        print(f\"Gen {g+1}/{gens} — best CV RMSE: {best[0]:.4f} | best params: {best[1]}\")\n",
        "    return best, history\n",
        "\n",
        "start = time.time()\n",
        "(best_tuple, cv_curve) = orchard_optimize(X_train_s, y_train, pop=10, gens=6, elite=3)\n",
        "print(f\"OA done in {time.time()-start:.1f}s\")\n",
        "best_cv_rmse, best_params = best_tuple[0], best_tuple[1]\n",
        "best_params, best_cv_rmse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kNxoJF-p8mHa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import copy, random\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "def boa_feature_selection(\n",
        "    X_train, y_train,              # unscaled train features/target\n",
        "    feature_names,                 # list[str]\n",
        "    generations=8, pop_size=12, elite=3,\n",
        "    phi=0.89                       # penalty weight (paper)\n",
        "):\n",
        "    n_feat = X_train.shape[1]\n",
        "    assert n_feat == len(feature_names)\n",
        "\n",
        "    # 1) Importance from RF on TRAIN ONLY (normalize to sum=1 for penalty)\n",
        "    rf_all = RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1)\n",
        "    rf_all.fit(X_train, y_train)\n",
        "    imp = rf_all.feature_importances_\n",
        "    imp = imp / (imp.sum() + 1e-12)\n",
        "\n",
        "    # Helper: CV RMSE for a given feature mask using RF (fast proxy)\n",
        "    def cv_rmse(mask, n_splits=3):\n",
        "        idx = np.where(mask == 1)[0]\n",
        "        if len(idx) == 0:\n",
        "            return np.inf\n",
        "        X = X_train[:, idx]\n",
        "        kf = KFold(n_splits=min(n_splits, len(y_train)), shuffle=True, random_state=42)\n",
        "        rmses = []\n",
        "        for tr, va in kf.split(X):\n",
        "            X_tr, X_va = X[tr], X[va]\n",
        "            y_tr, y_va = y_train[tr], y_train[va]\n",
        "            m = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "            m.fit(X_tr, y_tr)\n",
        "            p = m.predict(X_va)\n",
        "            rmses.append(np.sqrt(mean_squared_error(y_va, p)))\n",
        "        return float(np.mean(rmses)) if len(rmses) > 0 else np.inf\n",
        "\n",
        "    # Objective = CV_RMSE + log(1 + #features) + phi * penalty(dropping important feats)\n",
        "    def objective(mask):\n",
        "        rmse = cv_rmse(mask)\n",
        "        k = mask.sum()\n",
        "        # penalty for excluding important features\n",
        "        penalty = phi * float(np.sum((1 - mask) * imp))\n",
        "        return rmse + np.log1p(k) + penalty\n",
        "\n",
        "    # Init population (avoid all-zero)\n",
        "    population = []\n",
        "    for _ in range(pop_size):\n",
        "        m = np.random.randint(0, 2, n_feat)\n",
        "        if m.sum() == 0:\n",
        "            m[np.random.randint(0, n_feat)] = 1\n",
        "        population.append(m)\n",
        "\n",
        "    best_score, best_mask = np.inf, None\n",
        "    history = []\n",
        "\n",
        "    for g in range(generations):\n",
        "        scored = []\n",
        "        for m in population:\n",
        "            s = objective(m)\n",
        "            scored.append((s, m))\n",
        "            if s < best_score:\n",
        "                best_score, best_mask = s, m.copy()\n",
        "\n",
        "        scored.sort(key=lambda x: x[0])\n",
        "        elites = [scored[i][1].copy() for i in range(min(elite, len(scored)))]\n",
        "\n",
        "        # Mutations (growth/grafting)\n",
        "        mutants = []\n",
        "        for e in elites:\n",
        "            # single flip\n",
        "            m1 = e.copy()\n",
        "            i = np.random.randint(0, n_feat)\n",
        "            m1[i] = 1 - m1[i]\n",
        "            if m1.sum() == 0: m1[i] = 1\n",
        "            mutants.append(m1)\n",
        "            # double flip\n",
        "            m2 = e.copy()\n",
        "            i, j = np.random.randint(0, n_feat, size=2)\n",
        "            m2[i] = 1 - m2[i]\n",
        "            m2[j] = 1 - m2[j]\n",
        "            if m2.sum() == 0: m2[np.random.randint(0, n_feat)] = 1\n",
        "            mutants.append(m2)\n",
        "\n",
        "        # Fresh random individuals (screening/diversity)\n",
        "        fresh = []\n",
        "        while len(elites) + len(mutants) + len(fresh) < pop_size:\n",
        "            m = np.random.randint(0, 2, n_feat)\n",
        "            if m.sum() == 0:\n",
        "                m[np.random.randint(0, n_feat)] = 1\n",
        "            fresh.append(m)\n",
        "\n",
        "        population = elites + mutants + fresh\n",
        "        history.append(best_score)\n",
        "        print(f\"BOA gen {g+1}/{generations} — best score: {best_score:.4f} | selected: {best_mask.sum()}\")\n",
        "\n",
        "    sel_idx = np.where(best_mask == 1)[0]\n",
        "    sel_names = [feature_names[i] for i in sel_idx]\n",
        "    return best_mask, sel_idx, sel_names, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eHCRmkyHEdd",
        "outputId": "d3084439-3605-47ea-d7fd-ced2852c971d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOA gen 1/8 — best score: 6.0388 | selected: 1\n",
            "BOA gen 2/8 — best score: 6.0388 | selected: 1\n",
            "BOA gen 3/8 — best score: 6.0388 | selected: 1\n",
            "BOA gen 4/8 — best score: 6.0388 | selected: 1\n",
            "BOA gen 5/8 — best score: 6.0388 | selected: 1\n",
            "BOA gen 6/8 — best score: 6.0388 | selected: 1\n",
            "BOA gen 7/8 — best score: 6.0388 | selected: 1\n",
            "BOA gen 8/8 — best score: 6.0388 | selected: 1\n",
            "Selected features: ['rain_idw']\n",
            "Reduced shapes: (18, 1) (22, 1)\n"
          ]
        }
      ],
      "source": [
        "# Use TRAIN ONLY to decide features\n",
        "feature_cols_current = feature_cols[:]  # from earlier split cell\n",
        "mask, sel_idx, sel_names, boa_hist = boa_feature_selection(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    feature_names=feature_cols_current,\n",
        "    generations=8, pop_size=12, elite=3, phi=0.89\n",
        ")\n",
        "\n",
        "print(\"Selected features:\", sel_names)\n",
        "\n",
        "# Build reduced matrices\n",
        "X_train_red = X_train[:, sel_idx]\n",
        "X_test_red  = X_test[:, sel_idx]\n",
        "\n",
        "# Re-scale (fit on train only)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler_red = StandardScaler()\n",
        "X_train_red_s = scaler_red.fit_transform(X_train_red)\n",
        "X_test_red_s  = scaler_red.transform(X_test_red)\n",
        "\n",
        "print(\"Reduced shapes:\", X_train_red_s.shape, X_test_red_s.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMkQR54mIe-u",
        "outputId": "d4c8bd4d-4ee7-4a66-f3d0-87435c2582bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gen 1/5 — best CV RMSE: 29.8697 | best params: {'units': 24, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 4, 'epochs': 120}\n",
            "Gen 2/5 — best CV RMSE: 29.7564 | best params: {'units': 24, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 4, 'epochs': 120}\n",
            "Gen 3/5 — best CV RMSE: 28.9501 | best params: {'units': 32, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 4, 'epochs': 120}\n",
            "Gen 4/5 — best CV RMSE: 28.9501 | best params: {'units': 32, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 4, 'epochs': 120}\n",
            "Gen 5/5 — best CV RMSE: 28.9501 | best params: {'units': 32, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 4, 'epochs': 120}\n",
            "Best OA-LSTM (reduced) CV RMSE: 28.950068996301287 params: {'units': 32, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 4, 'epochs': 120}\n",
            "OA-LSTM (reduced features) — TEST: {'RMSE': 24.080993570279457, 'R2': -26.265985183350885, 'SD': 5.090042516678624}\n"
          ]
        }
      ],
      "source": [
        "# Reuse orchard_optimize and build_lstm from earlier\n",
        "# Prepare seq tensors with reduced features\n",
        "X_train_red_seq = X_train_red_s.reshape((X_train_red_s.shape[0], 1, X_train_red_s.shape[1]))\n",
        "X_test_red_seq  = X_test_red_s.reshape((X_test_red_s.shape[0], 1, X_test_red_s.shape[1]))\n",
        "\n",
        "# Slightly fewer generations since feature space is already pruned\n",
        "(best_tuple_red, cv_curve_red) = orchard_optimize(X_train_red_s, y_train, pop=10, gens=5, elite=3)\n",
        "best_cv_rmse_red, best_params_red = best_tuple_red[0], best_tuple_red[1]\n",
        "print(\"Best OA-LSTM (reduced) CV RMSE:\", best_cv_rmse_red, \"params:\", best_params_red)\n",
        "\n",
        "# Train final OA-LSTM on reduced feature set\n",
        "final_lstm_red = build_lstm(\n",
        "    input_shape=(1, X_train_red_s.shape[1]),\n",
        "    units=best_params_red[\"units\"],\n",
        "    dropout=best_params_red[\"dropout\"],\n",
        "    lr=best_params_red[\"lr\"]\n",
        ")\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(patience=20, restore_best_weights=True)\n",
        "final_lstm_red.fit(\n",
        "    X_train_red_seq, y_train,\n",
        "    validation_split=0.25,\n",
        "    epochs=best_params_red[\"epochs\"],\n",
        "    batch_size=best_params_red[\"batch_size\"],\n",
        "    verbose=0,\n",
        "    callbacks=[es]\n",
        ")\n",
        "pred_oa_red = final_lstm_red.predict(X_test_red_seq, verbose=0).ravel()\n",
        "print(\"OA-LSTM (reduced features) — TEST:\", evaluate(y_test, pred_oa_red))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "5KlHk76bIjTu",
        "outputId": "a9161e01-d1a4-4f22-9a77-230856677c0b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Random Forest\",\n          \"SVM\",\n          \"LSTM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.808158399320801,\n        \"min\": 3.2659205414723176,\n        \"max\": 24.888530253678866,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.2659205414723176,\n          3.9655513932073716,\n          24.888530253678866\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.899855993440243,\n        \"min\": -28.125332544411624,\n        \"max\": 0.49848535508258907,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.49848535508258907,\n          0.26059981272135535,\n          -28.125332544411624\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.10652929665265,\n        \"min\": 3.2396363061433413,\n        \"max\": 11.682091407398493,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.2396363061433413,\n          3.965551392991338,\n          4.343886208501631\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4c7960f9-5f95-40a8-99f4-602649c177d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "      <th>SD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>3.265921</td>\n",
              "      <td>0.498485</td>\n",
              "      <td>3.239636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVM</td>\n",
              "      <td>3.965551</td>\n",
              "      <td>0.260600</td>\n",
              "      <td>3.965551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DNN (fixed)</td>\n",
              "      <td>14.708909</td>\n",
              "      <td>-9.172631</td>\n",
              "      <td>11.682091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RNN</td>\n",
              "      <td>21.494908</td>\n",
              "      <td>-20.724188</td>\n",
              "      <td>4.463840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>OA-LSTM BOA</td>\n",
              "      <td>24.080994</td>\n",
              "      <td>-26.265985</td>\n",
              "      <td>5.090043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>24.888530</td>\n",
              "      <td>-28.125333</td>\n",
              "      <td>4.343886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>OA-LSTM full</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c7960f9-5f95-40a8-99f4-602649c177d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c7960f9-5f95-40a8-99f4-602649c177d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c7960f9-5f95-40a8-99f4-602649c177d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7228ead6-a3d3-4d0f-8d85-6335e09980d1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7228ead6-a3d3-4d0f-8d85-6335e09980d1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7228ead6-a3d3-4d0f-8d85-6335e09980d1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           Model       RMSE         R2         SD\n",
              "0  Random Forest   3.265921   0.498485   3.239636\n",
              "1            SVM   3.965551   0.260600   3.965551\n",
              "2    DNN (fixed)  14.708909  -9.172631  11.682091\n",
              "3            RNN  21.494908 -20.724188   4.463840\n",
              "6    OA-LSTM BOA  24.080994 -26.265985   5.090043\n",
              "4           LSTM  24.888530 -28.125333   4.343886\n",
              "5   OA-LSTM full        NaN        NaN        NaN"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def row(name, scores):\n",
        "    return {\"Model\": name, **scores}\n",
        "\n",
        "results = []\n",
        "results.append(row(\"Random Forest\", evaluate(y_test, pred_rf)))\n",
        "results.append(row(\"SVM\",           evaluate(y_test, pred_svm)))\n",
        "results.append(row(\"DNN (fixed)\",   evaluate(y_test, pred_dnn)))\n",
        "results.append(row(\"RNN\",           evaluate(y_test, pred_rnn)))\n",
        "results.append(row(\"LSTM\",          evaluate(y_test, pred_lstm)))\n",
        "results.append(row(\"OA-LSTM full\",  evaluate(y_test, pred_oa) if 'pred_oa' in locals() else {\"RMSE\": np.nan, \"R2\": np.nan, \"SD\": np.nan}))\n",
        "results.append(row(\"OA-LSTM BOA\",   evaluate(y_test, pred_oa_red)))\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(results).sort_values(\"RMSE\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
